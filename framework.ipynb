{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import localtime, strftime\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (15, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of samples in each class\n",
    "\n",
    "TEST_SAMPLE_NUMBER = 57092\n",
    "TRAIN_SAMPLE_NUMBER = 285998\n",
    "\n",
    "# array1: [sX1; sY1; sX2; sY2; ...]\n",
    "# array2: [eX1; eY1; eX2; eY2; ...]\n",
    "# output: [dist((sX1, sY1), (eX1, eY1)), dist((sX1, sY1), (eX1, eY1)),\n",
    "#          dist((sX2, sY2), (eX2, eY2)), dist((sX2, sY2), (eX2, eY2)), ...]\n",
    "\n",
    "def distance_for_each_point(array1, array2):\n",
    "    assert (len(array1) == len(array2)), \"Arrays' sizes have to be equal (array1: {}, array2: {})\".format(\n",
    "        len1=len(array1), len2=len(array2))\n",
    "    \n",
    "    array_length = len(array1)\n",
    "    \n",
    "    # for one-dimension arrays np.linalg.norm works in one way and for two-dimension in other\n",
    "    if array1.ndim == 1:\n",
    "        # array1[i:i+2] -- point i from first array\n",
    "        # np.linalg.norm -- calculate distance between points\n",
    "        distance = np.array([np.linalg.norm(array1[i:i+2] - array2[i:i+2]) for i in range(0,array_length,2)])\n",
    "        result = np.array([[d, d] for d in distance]).flatten()\n",
    "    else:\n",
    "        result = np.array([distance_for_each_point(array1[i], array2[i]) for i in range(array_length)])\n",
    "    \n",
    "    return result\n",
    "\n",
    "# metrics between real results (in tests) and predicted\n",
    "def distance(test_results, predicted_results):\n",
    "    return distance_for_each_point(np.array(test_results), predicted_results).sum() / TEST_SAMPLE_NUMBER / 2\n",
    "\n",
    "# data may be present as [n_features * n_samples] or [n_samples * n_features] \n",
    "# usually algorithms require second variant but I prefer first\n",
    "def to_model(df):\n",
    "    return np.array(df).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you need to pass as arguments function to execute, test_results to compare with predicted by function,\n",
    "# parameter_name to know results by which parameter you want to compare and list_of_values for this parameter\n",
    "# also you need to pass other argument which function will use \n",
    "# it's always some test_data and usually train_data and train_results\n",
    "\n",
    "def compare_results(function, test_results, parameter_name, list_of_values, **other_parameters):\n",
    "    log_file_name = \"src/Logs/{date}_predicted_coordinates_{function_name}_{parameter_name}_\".format(\n",
    "        date=strftime(\"%Y%m%d\", localtime()), function_name=function.__name__, parameter_name=parameter_name)\n",
    "    plot_file_name = \"src/Plots/{date}_{function_name}_difference_by_{parameter_name}.png\".format(\n",
    "        date=strftime(\"%Y%m%d\", localtime()), function_name=function.__name__, parameter_name=parameter_name)\n",
    "    \n",
    "    # we will keep results for each configuration here\n",
    "    result = []\n",
    "\n",
    "    for i, value in enumerate(list_of_values):\n",
    "        print(\"{cur}/{num}: {time}\".format(cur=i+1, num=len(list_of_values),\n",
    "                                           time=strftime(\"%Y-%m-%d %H:%M:%S\", localtime())))\n",
    "        other_parameters[parameter_name] = value        \n",
    "        predicted_results = function(**other_parameters)\n",
    "        np.save(log_file_name + str(value), predicted_results)\n",
    "        result.append(distance(test_results, predicted_results))\n",
    "        \n",
    "    print(\"done! {time}\".format(time=strftime(\"%Y-%m-%d %H:%M:%S\", localtime())))\n",
    "    print(\"Results: {}\".format(result))\n",
    "        \n",
    "    ind = list_of_values\n",
    "    number = len(ind)\n",
    "    width = 2 / number\n",
    "    result_bar = plt.bar(range(number), result, width, color='g')\n",
    "\n",
    "    plt.ylabel('Average difference')\n",
    "    plt.xlabel(parameter_name)\n",
    "    plt.title(\"Difference between real points and predicted by {parameter_name} in {function_name}\".format(\n",
    "        function_name=function.__name__, parameter_name=parameter_name))\n",
    "    plt.xticks(np.array(range(number)) + width/2, ind)\n",
    "    plt.savefig(plot_file_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reading data from .csv files\n",
    "\n",
    "test_data = pd.read_csv('src/test_data_points.csv', index_col=0)\n",
    "train_data = pd.read_csv('src/train_data_points.csv', index_col=0)\n",
    "\n",
    "# split ten frames in input and output data (we want to predict output by input)\n",
    "\n",
    "test_results = test_data[5:10]\n",
    "test_data = test_data[:5]\n",
    "\n",
    "train_results = train_data[5:10]\n",
    "train_data = train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# n_neighbors by defalt is 5;         to compare: range(5, 55, 5)\n",
    "# weights     by defalt is 'uniform'; to compare: ['uniform', 'distance']\n",
    "# algorithm   by defalt is 'auto';    to compare: ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "# note: 'brute' is causing some memory error\n",
    "\n",
    "def kneighbors_regressor(train_data, train_results, test_data, **kwargs):\n",
    "    neigh = KNeighborsRegressor(**kwargs)\n",
    "    neigh.fit(to_model(train_data), to_model(train_results))\n",
    "    return (neigh.predict(to_model(test_data))).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no difference which algorithm to use: ball_tree or kd_tree but kd_tree works faster. Also between 'uniform' and 'distance' (parameter weights) there is no difference neither.\n",
    "The optimal n_neighbors is 25."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note: I deleted some cells with comparison. You could find them in previous versions of this notebook on github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
